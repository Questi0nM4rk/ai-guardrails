
## AI Guardrails - Code Standards

This project uses [ai-guardrails](https://github.com/Questi0nM4rk/ai-guardrails) for pedantic code enforcement.

### Philosophy

**Hard stops only.** No warnings, no suggestions. Everything is an error or it's ignored.

**Local:** Auto-fix everything possible. Don't waste context on syntax/formatting.
**CI/CD:** Check only, never modify code.

### Pre-commit Workflow

```
auto-fix → re-stage → checks → commit
```

1. `format-and-stage` auto-fixes ALL fixable issues and re-stages (local only, skipped in CI)
   - Python: `ruff format` + `ruff check --fix`
   - Shell: `shfmt`
   - Markdown: `markdownlint --fix`
   - TypeScript/JS: `biome check --write`
   - TOML: `taplo format`
2. Security scans (gitleaks, detect-secrets, semgrep)
3. Linting - checks only, already fixed above
4. Type checking (strict mode)
5. Git hygiene (no commits to main, no large files)

### Language-Specific Rules

**Python:**
- `from __future__ import annotations` required in ALL files (auto-added by ruff)
- Type hints required on all function signatures
- Docstrings required on public functions/classes
- No bare `except:` - always specify exception type
- Use `X | None` not `Optional[X]`

**TypeScript/JavaScript:**
- Strict mode (`"strict": true` in tsconfig)
- No `any` type - use `unknown` and narrow
- No `console.log` in production code
- JSDoc on exported functions

**Shell (Bash):**
- `set -euo pipefail` at script start
- Quote all variables: `"$var"` not `$var`
- Use `[[` not `[` for conditionals
- Prefer portable POSIX syntax where possible

### Test Requirements

- Tests required for new functionality
- Test files must be named `test_*.py` or `*_test.py`
- Meaningful assertions (not just "no errors")
- No shared state between tests

### Review Bots

All bots auto-review every push. No manual triggers needed.

| Bot | Focus | Trigger |
|-----|-------|---------|
| CodeRabbit | Static analysis, security, language conventions | Auto on push |
| Claude | Code duplication, clean code, modern patterns, architecture | Auto on PR |
| Gemini | Bugs, logic errors, security, performance | Auto on push |
| DeepSource | Anti-patterns, OWASP, code metrics | Auto on push |

**Rules for AI Agents:**

Every push triggers all 4 review bots. Unnecessary pushes waste review cycles
and create noise. Only push when you are confident the code is complete.

1. **Complete all changes before pushing** — Finish the entire task locally (all files, all fixes, all tests passing). Do not push work-in-progress
2. **Never auto-push** — Always ask the human before running `git push`. Explain what changed and confirm they want a review
3. **Batch into minimal commits** — Group related changes into logical commits. Push them all at once
4. **Address ALL review feedback before pushing again** — When bots request changes, fix every comment locally, then push once. Do not push after each individual fix
5. **Wait for all bots** — After pushing, wait for all reviews to complete (~5 min) before acting on feedback

### When Pre-commit Fails

Most syntax/formatting issues are auto-fixed. If pre-commit still fails:

1. Read the error message - it's a non-auto-fixable issue
2. Fix the actual problem (missing docstring, type error, security issue)
3. Stage and commit again

Common non-auto-fixable issues:
- Missing docstrings → Write them
- Type errors → Fix the types
- Security issues → Fix the vulnerability
- Missing `from __future__ import annotations` → Add it (or let ruff add it)
