{
	"reviews": [
		{
			"id": "PRR_kwDOQ91llM7cfYsd",
			"author": { "login": "coderabbitai" },
			"authorAssociation": "NONE",
			"body": "**Actionable comments posted: 8**\n\n<details>\n<summary>ü§ñ Fix all issues with AI agents</summary>\n\n```\nIn @.pre-commit-config.yaml:\n- Around line 66-72: The codespell pre-commit hook currently includes the\n\"--write-changes\" arg which auto-modifies files; remove that flag from the args\nfor the hook with id \"codespell\" so the hook only reports typos (e.g., leave\n\"--check-filenames\" or other non-mutating args) to align with the repository's\nno-auto-fix policy and ruff.toml's fix = false.\n- Around line 97-103: The pip-audit hook (id: pip-audit) is missing a dependency\nsource so it only scans the hook environment; update the hook's args entry (the\nargs array under the pip-audit hook) to include either a requirements file\n(e.g., add \"-r\", \"requirements.lock\" or \"-r\", \"requirements.txt\") or the\nlocked-mode flag (e.g., \"--locked\", \".\") so pip-audit scans your project\ndependencies rather than the isolated env.\n\nIn `@bin/ai-guardrails-init`:\n- Around line 100-103: The auto-detect conditional incorrectly uses [[ -f\n\"*.sln\" ]] which never matches globs; update the if that currently reads the\ncombined check (the conditional containing [[ -f \"*.csproj\" ]] || [[ -f \"*.sln\"\n]] || ls ./*.csproj 1>/dev/null 2>&1) to perform a proper existence test for\n.sln files (for example use a glob-aware check such as invoking ls ./*.sln\n1>/dev/null 2>&1 or using compgen -G \"*.sln\" >/dev/null) so repos containing\nonly .sln files are detected and types includes \"dotnet\".\n\nIn `@lib/python/coderabbit_parser.py`:\n- Around line 104-130: The current extract_analysis_chain function uses a\nnon-greedy regex to find the <details> block which will prematurely stop if the\nanalysis chain contains nested </details>; replace the fragile regex-based\nextraction with an HTML parser (e.g., BeautifulSoup or html.parser) to locate\nthe <details> element whose <summary> text equals \"üß© Analysis chain\", then\nextract its full inner HTML/text (preserving any nested <details>) and continue\nrunning the existing script_match and output_match logic against that extracted\ncontent; update function references to extract_analysis_chain and keep the\nsubsequent script/output regexes unchanged, only changing how the details block\nis located and extracted.\n- Around line 263-267: The regex for parsing file detail blocks in\ncoderabbit_parser.py (currently assigned to file_pattern) duplicates a pattern\nthat fails for extensionless filenames; extract and replace it with a\nmodule-level constant named FILE_BLOCK_PATTERN using the corrected pattern (the\nsuggested pattern that captures names without relying on a dot:\nr\"<details>\\s*<summary>([^<(]+?)\\s*\\(\\d+\\)</summary>\\s*<blockquote>(.*?)</blockquote>\\s*</details>\"\nwith re.DOTALL) and update all references (including the usage in\nparse_outside_diff_section and where file_pattern is defined) to use\nFILE_BLOCK_PATTERN to keep behavior consistent across the file.\n- Around line 206-209: The current regex assigned to file_pattern\n(r\"<details>\\s*<summary>([^<]+\\.\\w+)\\s*\\(\\d+\\)</summary>\\s*<blockquote>(.*?)</blockquote>\\s*</details>\",\nre.DOTALL) forces a dot-extension; update the capture for the filename in\nfile_pattern to accept any filename (including extensionless or non-word\nextensions) by capturing everything up to the count parenthesis, e.g. replace\nthe filename group with a non-greedy capture like ([^<]+?)\\s*\\(\\d+\\), and keep\nthe rest of the pattern and re.DOTALL unchanged so files like Makefile,\nDockerfile, or .gitignore are matched by the file_pattern.\n\nIn `@README.md`:\n- Around line 121-123: Fix the typo in the README list item: change the word\n\"create\" to \"crate\" in the line that currently reads \"Imports grouped by\nstd/external/create\" so it correctly describes Rust import grouping as \"Imports\ngrouped by std/external/crate\"; update that exact phrase in README.md.\n\nIn `@templates/pre-commit-config.yaml`:\n- Around line 6-16: The pre-commit tool versions for several hooks are outdated:\nupdate the versions for semgrep to v1.149.0, conventional-pre-commit to v4.3.0,\ncodespell to v2.4.1, and pip-audit to v2.10.0 in the pre-commit config (update\nthe entries for semgrep, conventional-pre-commit, codespell, pip-audit),\npreserving the existing hook IDs and CLI flags/args for each hook and leaving\ndetect-secrets and taplo-pre-commit unchanged; after updating, run pre-commit\nautoupdate or validate the YAML to ensure syntax stays valid and the updated\nversions resolve correctly.\n```\n\n</details>\n\n<details>\n<summary>üßπ Nitpick comments (3)</summary><blockquote>\n\n<details>\n<summary>README.md (1)</summary><blockquote>\n\n`133-134`: **Grammar: Use hyphen for compound modifier.**\n\nPer the static analysis hint, \"2 space indent\" should be hyphenated when used as a compound modifier.\n\n\n\n<details>\n<summary>üìù Grammar fix</summary>\n\n```diff\n-- 120 char lines, 2 space indent\n+- 120-char lines, 2-space indent\n```\n\n</details>\n\n</blockquote></details>\n<details>\n<summary>.pre-commit-config.yaml (1)</summary><blockquote>\n\n`42-48`: **Semgrep `--config auto` may introduce variability.**\n\nUsing `--config auto` pulls rules from the Semgrep registry, which can change over time. This may cause previously passing code to fail unexpectedly when new rules are added.\n\n\n\nConsider pinning to a specific ruleset for reproducibility:\n\n```yaml\nargs: [\"--config\", \"p/default\", \"--config\", \"p/owasp-top-ten\", \"--error\"]\n```\n\nOr document that `auto` is intentional for staying current with security best practices.\n\n</blockquote></details>\n<details>\n<summary>configs/ruff.toml (1)</summary><blockquote>\n\n`62-63`: **Consider the tradeoffs of requiring `from __future__ import annotations` in all files.**\n\nThis enables PEP 563 deferred evaluation of annotations (stored as strings), which avoids circular imports and forward references. However, this causes runtime issues when code relies on evaluating annotations at runtime‚Äînotably with `get_type_hints()` calls, Pydantic models, dataclass validators, and ORMs. These issues are most acute when types are defined in local scopes or are missing from the evaluation namespace, but they have documented mitigations: keeping types at module level, passing explicit namespaces to `get_type_hints()`, and using library-specific rebuild patterns (e.g., `model_rebuild()` in Pydantic v2). Worth reviewing whether this tradeoff aligns with your codebase's patterns, though note that PEP 563 is being superseded in favor of lazy annotation evaluation via PEP 649/749.\n\n</blockquote></details>\n\n</blockquote></details>\n\n<!-- This is an auto-generated comment by CodeRabbit for review status -->",
			"submittedAt": "2026-01-23T19:25:23Z",
			"includesCreatedEdit": false,
			"reactionGroups": [],
			"state": "COMMENTED",
			"commit": { "oid": "105b7522b6505444c61456b37ef73ba3ce934679" }
		}
	]
}
